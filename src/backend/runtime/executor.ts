import type { QueuedRun } from '../../types/api.js';
import type { LLMConfig } from '../../types/agent.js';
import type { SSEManager } from '../api/sse.js';
import { logger } from '../../utils/logger.js';
import { McpConnectionManager, type McpServerConfig } from './mcp-connection-manager.js';
import type { MemoryService } from './memory-service.js';
import { RuntimeToolRouter } from './tool-router.js';
import { SkillLoader } from './skill/loader.js';
import { ToolCallScheduler, ToolApprovalManager } from './tool-scheduler.js';
import { EscalationService } from './escalation-service.js';
import type { CheckpointService } from './checkpoint-service.js';
import type { EventService } from './event-service.js';
import type { GroupRepository } from './group-repository.js';
import type { RoleRepository } from './role-repository.js';
import type { RunRepository } from './run-repository.js';
import type { SkillRepository } from './skill/repository.js';
import type { FeishuSyncService } from './integrations/feishu/sync-service.js';
import type { MineruIngestService } from './integrations/mineru/ingest-service.js';
import { refreshSkillRegistry } from './executor/skill-refresh.js';
import { executeSingleRun } from './executor/single-run.js';
import { executeGroupRun } from './executor/group-run.js';

type Scope = { orgId: string; userId: string; projectId: string | null };
type RunTerminalStatus = 'completed' | 'failed' | 'cancelled' | 'suspended';

// ─── Config & Result ─────────────────────────────────────────

export interface RuntimeExecutorConfig {
  runRepository: RunRepository;
  eventService: EventService;
  checkpointService: CheckpointService;
  memoryService: MemoryService;
  skillRepository: SkillRepository;
  sseManager: SSEManager;
  groupRepository: GroupRepository;
  roleRepository: RoleRepository;
  feishuSyncService?: FeishuSyncService;
  mineruIngestService?: MineruIngestService;
  maxSteps: number;
  defaultModelConfig: LLMConfig;
  workDir: string;
  mcp?: {
    enabled: boolean;
    pythonPath?: string;
    serverModule?: string;
    cwd?: string;
    timeoutMs?: number;
  };
  mcpServers?: McpServerConfig[];
  skillPaths?: string[];
  enableImplicitSkills?: boolean;
  budget?: {
    maxContextTokens?: number;
    compactionThreshold?: number;
    warningThreshold?: number;
    reserveTokens?: number;
  };
  persistLlmTokens?: boolean;
  runQueue?: { notifyRunWaiting(runId: string): void; notifyRunResumed(runId: string): void };
  swarmCoordinator?: import('./swarm-coordinator.js').SwarmCoordinator;
}

export interface RuntimeExecutorResult {
  execute: (run: QueuedRun, signal: AbortSignal) => Promise<{ status: RunTerminalStatus }>;
  approvalManager: ToolApprovalManager;
}

// ─── Helpers ─────────────────────────────────────────────────

function isCancellationError(error: unknown): boolean {
  if (!error || typeof error !== 'object') return false;
  const e = error as { name?: string; message?: string };
  if (e.name === 'AbortError' || e.name === 'RunCancelledError') return true;
  const msg = (e.message ?? '').toLowerCase();
  return msg.includes('aborted') || msg.includes('cancelled');
}

function resolveModelConfig(run: QueuedRun, defaults: LLMConfig): LLMConfig {
  const provider = run.llm_config?.provider ?? defaults.provider;
  const model = run.llm_config?.model ?? defaults.model;
  const mc: LLMConfig = { provider, model };

  if (provider === defaults.provider && defaults.apiKey) mc.apiKey = defaults.apiKey;
  if (run.llm_config?.base_url) mc.baseUrl = run.llm_config.base_url;
  else if (provider === defaults.provider && defaults.baseUrl) mc.baseUrl = defaults.baseUrl;

  const temperature = run.llm_config?.temperature ?? defaults.temperature;
  if (temperature !== undefined) mc.temperature = temperature;
  const maxTokens = run.llm_config?.max_tokens ?? defaults.maxTokens;
  if (maxTokens !== undefined) mc.maxTokens = maxTokens;

  return mc;
}

// ─── Factory ─────────────────────────────────────────────────

export function createRuntimeExecutor(config: RuntimeExecutorConfig): RuntimeExecutorResult {
  let sharedToolRouter: RuntimeToolRouter | null = null;
  let sharedToolRouterInit: Promise<RuntimeToolRouter> | null = null;
  let sharedMcpManager: McpConnectionManager | null = null;
  let sharedSkillLoader: SkillLoader | null = null;
  const sharedApprovalManager = new ToolApprovalManager();
  const sharedToolScheduler = new ToolCallScheduler({ approvalManager: sharedApprovalManager });

  async function getSkillLoader(): Promise<SkillLoader> {
    if (sharedSkillLoader) return sharedSkillLoader;
    const loader = new SkillLoader();
    if (config.skillPaths && config.skillPaths.length > 0) {
      await loader.discover(config.skillPaths);
    }
    sharedSkillLoader = loader;
    return loader;
  }

  async function getMcpManager(): Promise<McpConnectionManager | null> {
    if (sharedMcpManager) return sharedMcpManager;
    if (!config.mcpServers || config.mcpServers.length === 0) return null;
    const manager = new McpConnectionManager();
    await manager.initialize(config.mcpServers);
    sharedMcpManager = manager;
    return manager;
  }

  async function getSharedToolRouter(scope: Scope): Promise<RuntimeToolRouter> {
    if (sharedToolRouter) {
      sharedToolRouter.setScope(scope);
      await refreshSkillRegistry(sharedToolRouter, config.skillRepository);
      return sharedToolRouter;
    }
    if (!sharedToolRouterInit) {
      sharedToolRouterInit = (async () => {
        const escalationService = new EscalationService({
          runRepository: config.runRepository,
          groupRepository: config.groupRepository,
        });
        const router = new RuntimeToolRouter({
          scope,
          memoryService: config.memoryService,
          eventService: config.eventService,
          ...(config.feishuSyncService ? { feishuSyncService: config.feishuSyncService } : {}),
          ...(config.mineruIngestService ? { mineruIngestService: config.mineruIngestService } : {}),
          workDir: config.workDir,
          ...(config.mcp ? { mcp: config.mcp } : {}),
          escalationService,
          groupRepository: config.groupRepository,
          runRepository: config.runRepository,
          roleRepository: config.roleRepository,
          ...(config.runQueue ? { runQueue: { enqueue: (runId: string) => config.runQueue!.notifyRunResumed(runId) } } : {}),
        });
        await router.start();
        sharedToolRouter = router;
        return router;
      })().catch((error) => {
        sharedToolRouterInit = null;
        throw error;
      });
    }
    const router = await sharedToolRouterInit;
    router.setScope(scope);
    await refreshSkillRegistry(router, config.skillRepository);
    return router;
  }

  const execute = async (run: QueuedRun, signal: AbortSignal): Promise<{ status: RunTerminalStatus }> => {
    const scope: Scope = {
      orgId: run.org_id,
      userId: run.user_id,
      projectId: run.project_id ?? null,
    };
    const modelConfig = resolveModelConfig(run, config.defaultModelConfig);

    if (signal.aborted) {
      await config.runRepository.setRunCancelled(run.run_id);
      return { status: 'cancelled' };
    }

    const toolRouter = await getSharedToolRouter(scope);
    const skillLoader = await getSkillLoader();
    const mcpManager = await getMcpManager();
    toolRouter.setRunContext(run.run_id, run.session_key);
    await config.runRepository.setRunRunning(run.run_id);

    try {
      const extras = { toolScheduler: sharedToolScheduler, skillLoader, mcpManager };
      const status = run.group_id
        ? await executeGroupRun(config, run, scope, modelConfig, toolRouter, signal, extras)
        : await executeSingleRun(config, run, scope, modelConfig, toolRouter, signal, extras);
      return { status };
    } catch (error: unknown) {
      if (signal.aborted || isCancellationError(error)) {
        await config.runRepository.setRunCancelled(run.run_id);
        logger.info('Runtime executor cancelled', { runId: run.run_id });
        return { status: 'cancelled' };
      }
      const message = error instanceof Error ? error.message : String(error);
      await config.runRepository.setRunFailed(run.run_id, { code: 'EXECUTOR_ERROR', message });
      logger.error('Runtime executor failed', { runId: run.run_id, error: message });
      return { status: 'failed' };
    }
  };

  return { execute, approvalManager: sharedApprovalManager };
}
